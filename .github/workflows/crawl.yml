name: MadMedCheck Data Crawling

on:
  # 매월 1일 오전 9시 (KST) 실행
  schedule:
    - cron: '0 0 1 * *'  # UTC 00:00 = KST 09:00, 매월 1일

  # 수동 실행도 가능
  workflow_dispatch:
    inputs:
      region:
        description: '크롤링 지역 (비워두면 전체)'
        required: false
        default: ''

env:
  # 필수 - 크롤링
  NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
  NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
  FIRECRAWL_API_KEY: ${{ secrets.FIRECRAWL_API_KEY }}
  # 필수 - AI 분석 (Gemini - 무료 크레딧 활용)
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  # 필수 - Cloudflare
  CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
  CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
  # 선택 - 구글 이미지 검색
  SERPAPI_KEY: ${{ secrets.SERPAPI_KEY }}

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run crawler
        id: crawl
        run: |
          if [ -n "${{ github.event.inputs.region }}" ]; then
            npx tsx scripts/run-pipeline.ts --region "${{ github.event.inputs.region }}"
          else
            npx tsx scripts/run-pipeline.ts
          fi

      - name: Upload SQL results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: crawl-results-${{ github.run_number }}
          path: crawl-results.sql
          if-no-files-found: ignore

      - name: Run D1 Migrations
        run: |
          npm install -g wrangler
          # 마이그레이션 파일들 실행 (오류 무시 - 이미 존재하는 컬럼)
          for f in migrations/*.sql; do
            echo "Running migration: $f"
            npx wrangler d1 execute madmedcheck-db --file="$f" --remote || true
          done
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}

      - name: Apply to D1 Database
        if: hashFiles('crawl-results.sql') != ''
        run: |
          npm install -g wrangler
          npx wrangler d1 execute madmedcheck-db --file=crawl-results.sql --remote
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}

      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::크롤링 실패. 로그를 확인하세요."

  # 크롤링 후 사이트 재빌드
  deploy:
    needs: crawl
    runs-on: ubuntu-latest
    if: success()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build site
        run: npm run build

      - name: Deploy to Cloudflare Pages
        run: npx wrangler pages deploy dist --project-name=score-madmedcheck
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
